# Этапы 1 — Онбординг и контур данных

1. Разобраться в текущей архитектуре [https://github.com/tunaeng/TutorAI](https://github.com/tunaeng/TutorAI): какие сущности и поля есть для групп, слушателей, посещаемости, выполнений, оценок, дедлайнов.
2. Подготовить план и реализовать API эндпоинтов чтения для n8n, договориться о форматах ответов и авторизации.
3. В n8n собрать черновой флоу: Cron → запрос конфигурации группы/периода в API → выбор слушателей недели → получение «фактов недели» на каждого.
4. Подготовить шаблон конфигурации группы/периода/программа (в API или отдельном конфиг-файле, который читает n8n): частота рассылки, лимит выборки, язык/тон, правила антиповтора.

# Этапы 2 — Расчёт weekly-score через Anthropic

1. Спроектировать промпт для расчёта weekly-score: вход — «сухие факты» недели; выход — structured JSON с полями: score, признаки для тай-брейка, индикатор «существенного прогресса», краткое объяснение решения.
2. Реализовать ноды в n8n: подготовка данных → вызов Anthropic (OpenRouter) → парсинг ответа → валидация структуры (guardrails на обязательные поля, fallback при ошибках).
3. В n8n добавить шаги отбора адресатов: применить антиповторы и тай-брейк на основе признаков, полученных от LLM.
4. Сохранить аудит решения (в API): входные факты, версия промпта, выход LLM, принятое решение по выборке.
5. Настроить режим «сухого прогона» без отправки сообщений (только расчёт и аудит), чтобы проверять корректность.

# Этапы 3 — Генерация персональных сообщений и Telegram

1. Спроектировать отдельный промпт для генерации сообщений: системный стиль, гайд по тактичной обратной связи, вставка фактов (прогресс, просрочки, ближайшие шаги).
2. В n8n собрать флоу: для выбранных адресатов → запрос Anthropic для текста → проверка обязательных фактов → отправка в Telegram-бота → фиксация статуса в API.
3. Добавить анти-дубликат формулировок (вариативность): лёгкая параметризация стиля, несколько подсказок-синонимизаторов, контроль повторов на уровне хэша текста.
4. Настроить обработку ошибок и ретраи: ошибки LLM, временные сбои Telegram, таймауты; аккуратные уведомления и повторные попытки.
5. Провести тест на тестовой группе и тестовых аккаунтах: проверить персонализацию, корректность ссылок/дат/дедлайнов.

# Этапы 4 — Конфигурируемость и «полировка» модели

1. Вынести параметры в конфиг группы/периода (читается n8n): расписание, лимит выборки, правила отбора, стиль/язык сообщений, включение «сухого прогона».
2. Добавить сервисные флоу в n8n: ручной перезапуск недели, просмотр истории, откат рассылки, экспорт аудита за период.
3. Провести сквозные проверки: Cron → API-факты → Anthropic-score → фильтры → Anthropic-сообщения → Telegram → аудит.
4. Сделать мини A/B вариации промптов и параметров Anthropic (через OpenRouter) для расчёта score и для генерации сообщений; выбрать стабильный профиль.
5. Зафиксировать «боевые» профили промптов (score/msg) и параметры вызова; описать порядок сопровождения и смены конфигов.
6. Подготовить краткое руководство: как добавить группу, включить/остановить рассылку, читать аудит, запускать «сухой прогон», обновлять промпты.

# Замечания по качеству и понятности

**Прозрачность решения:** всегда сохраняем «почему студент выбран/не выбран» (короткое объяснение из LLM + факты).

**Детерминизм там, где важно:** правила антиповтора и тай-брейка фиксированы в n8n; LLM даёт численный score и объяснение, но отбор — по правилам.

**Защита от ошибок:** валидация JSON-ответов LLM, контролируемые fallback-ветки, ретраи внешних вызовов.

**Понятность для кураторов:** человеческий лог аудита и возможность «сухого прогона» перед включением рассылки.
